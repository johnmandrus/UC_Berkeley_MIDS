{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f90408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091587b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "666a0139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea4df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 0\n",
    "ARCH = 'resnet18'\n",
    "EPOCHS = 200\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=256\n",
    "VAL_BATCH=256\n",
    "WORKERS=8\n",
    "TRAINDIR=\"/workspace/storage/train\"\n",
    "VALDIR=\"/workspace/storage/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf9aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "454511e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'tcp://3.19.70.152:1234'\n",
    "BACKEND = 'nccl'\n",
    "WORLD_SIZE = 2\n",
    "RANK = 0\n",
    "\n",
    "dist.init_process_group(backend = BACKEND, init_method= URL,\n",
    "                                 world_size= WORLD_SIZE, rank=RANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14df46c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = 0\n",
    "torch.cuda.set_device(GPU)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2834750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ff9405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f379ff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "399a634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebe69545",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb307fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    #lr = LR * (0.1 ** (epoch // 30))\n",
    "    lr = LR * (0.1 ** (epoch // 17))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdadd63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaea65fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed96c9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=imagenet_mean_RGB, std=imagenet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ca243b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 1000\n",
    "#model = models.resnet18()\n",
    "model = models.__dict__[ARCH]()\n",
    "inf = model.fc.in_features\n",
    "model.fc = nn.Linear(inf, NUM_CLASSES)\n",
    "model.cuda(GPU)\n",
    "model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[GPU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bf8f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)\n",
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b653d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = datasets.ImageFolder(\n",
    "#     TRAINDIR, transform=transform_train)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "613a45d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform_val = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "# ])\n",
    "\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "937854eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=torch.utils.data.distributed.DistributedSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c57edb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc046021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjohnmandrus\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install -q wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cf1bc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">golden-firebrand-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/johnmandrus/john-andrus-HW9-1node\" target=\"_blank\">https://wandb.ai/johnmandrus/john-andrus-HW9-1node</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/johnmandrus/john-andrus-HW9-1node/runs/3m2do4a4\" target=\"_blank\">https://wandb.ai/johnmandrus/john-andrus-HW9-1node/runs/3m2do4a4</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/storage/wandb/run-20210707_233304-3m2do4a4</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(3m2do4a4)</h1><iframe src=\"https://wandb.ai/johnmandrus/john-andrus-HW9-1node/runs/3m2do4a4\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f4c8c90b100>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"john-andrus-HW9-1node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a83cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/2503]\tTime 12.853 (12.853)\tData  3.507 ( 3.507)\tLoss 6.9781e+00 (6.9781e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   1.56 (  1.56)\n",
      "Epoch: [0][  50/2503]\tTime  0.788 ( 0.996)\tData  0.000 ( 0.069)\tLoss 6.8351e+00 (6.9405e+00)\tAcc@1   0.39 (  0.28)\tAcc@5   1.17 (  1.15)\n",
      "Epoch: [0][ 100/2503]\tTime  0.813 ( 0.900)\tData  0.000 ( 0.040)\tLoss 6.6011e+00 (6.8151e+00)\tAcc@1   0.39 (  0.44)\tAcc@5   1.95 (  1.71)\n",
      "Epoch: [0][ 150/2503]\tTime  1.163 ( 0.955)\tData  0.000 ( 0.031)\tLoss 6.2876e+00 (6.7147e+00)\tAcc@1   1.95 (  0.67)\tAcc@5   5.86 (  2.44)\n",
      "Epoch: [0][ 200/2503]\tTime  1.550 ( 1.045)\tData  0.000 ( 0.027)\tLoss 6.3867e+00 (6.6252e+00)\tAcc@1   0.39 (  0.82)\tAcc@5   2.34 (  3.06)\n",
      "Epoch: [0][ 250/2503]\tTime  1.330 ( 1.112)\tData  0.000 ( 0.025)\tLoss 6.2347e+00 (6.5463e+00)\tAcc@1   1.17 (  1.02)\tAcc@5   6.64 (  3.69)\n",
      "Epoch: [0][ 300/2503]\tTime  1.276 ( 1.149)\tData  0.000 ( 0.024)\tLoss 6.0568e+00 (6.4749e+00)\tAcc@1   0.78 (  1.21)\tAcc@5   7.81 (  4.26)\n",
      "Epoch: [0][ 350/2503]\tTime  1.276 ( 1.182)\tData  0.000 ( 0.023)\tLoss 6.0312e+00 (6.4104e+00)\tAcc@1   2.73 (  1.37)\tAcc@5  10.55 (  4.88)\n",
      "Epoch: [0][ 400/2503]\tTime  1.271 ( 1.205)\tData  0.000 ( 0.023)\tLoss 5.9721e+00 (6.3502e+00)\tAcc@1   2.34 (  1.55)\tAcc@5   8.98 (  5.46)\n",
      "Epoch: [0][ 450/2503]\tTime  1.258 ( 1.223)\tData  0.000 ( 0.022)\tLoss 5.7587e+00 (6.2933e+00)\tAcc@1   3.52 (  1.74)\tAcc@5  13.28 (  6.01)\n",
      "Epoch: [0][ 500/2503]\tTime  1.143 ( 1.238)\tData  0.000 ( 0.022)\tLoss 5.7847e+00 (6.2367e+00)\tAcc@1   2.34 (  1.94)\tAcc@5   9.77 (  6.58)\n",
      "Epoch: [0][ 550/2503]\tTime  1.316 ( 1.250)\tData  0.000 ( 0.021)\tLoss 5.5908e+00 (6.1839e+00)\tAcc@1   2.34 (  2.16)\tAcc@5  13.28 (  7.18)\n",
      "Epoch: [0][ 600/2503]\tTime  1.614 ( 1.260)\tData  0.000 ( 0.021)\tLoss 5.7330e+00 (6.1334e+00)\tAcc@1   2.73 (  2.36)\tAcc@5  10.55 (  7.74)\n",
      "Epoch: [0][ 650/2503]\tTime  1.560 ( 1.269)\tData  0.000 ( 0.021)\tLoss 5.5920e+00 (6.0842e+00)\tAcc@1   3.52 (  2.62)\tAcc@5  16.02 (  8.38)\n",
      "Epoch: [0][ 700/2503]\tTime  1.267 ( 1.276)\tData  0.000 ( 0.021)\tLoss 5.4972e+00 (6.0400e+00)\tAcc@1   6.25 (  2.83)\tAcc@5  16.41 (  8.93)\n",
      "Epoch: [0][ 750/2503]\tTime  1.471 ( 1.282)\tData  0.000 ( 0.020)\tLoss 5.3851e+00 (5.9969e+00)\tAcc@1   7.42 (  3.05)\tAcc@5  19.53 (  9.49)\n",
      "Epoch: [0][ 800/2503]\tTime  1.193 ( 1.288)\tData  0.000 ( 0.021)\tLoss 5.3974e+00 (5.9561e+00)\tAcc@1   5.86 (  3.27)\tAcc@5  18.36 ( 10.03)\n",
      "Epoch: [0][ 850/2503]\tTime  1.287 ( 1.293)\tData  0.000 ( 0.020)\tLoss 5.0135e+00 (5.9162e+00)\tAcc@1  10.94 (  3.48)\tAcc@5  26.56 ( 10.54)\n",
      "Epoch: [0][ 900/2503]\tTime  1.463 ( 1.296)\tData  0.000 ( 0.020)\tLoss 5.1018e+00 (5.8782e+00)\tAcc@1   9.77 (  3.69)\tAcc@5  23.05 ( 11.07)\n",
      "Epoch: [0][ 950/2503]\tTime  1.092 ( 1.300)\tData  0.000 ( 0.020)\tLoss 5.2782e+00 (5.8417e+00)\tAcc@1   6.25 (  3.92)\tAcc@5  19.53 ( 11.58)\n",
      "Epoch: [0][1000/2503]\tTime  0.999 ( 1.304)\tData  0.000 ( 0.020)\tLoss 5.0837e+00 (5.8045e+00)\tAcc@1  10.55 (  4.13)\tAcc@5  22.27 ( 12.10)\n",
      "Epoch: [0][1050/2503]\tTime  1.153 ( 1.307)\tData  0.000 ( 0.020)\tLoss 4.9981e+00 (5.7698e+00)\tAcc@1   7.81 (  4.35)\tAcc@5  23.83 ( 12.59)\n",
      "Epoch: [0][1100/2503]\tTime  1.283 ( 1.310)\tData  0.000 ( 0.020)\tLoss 4.8922e+00 (5.7355e+00)\tAcc@1  12.89 (  4.58)\tAcc@5  25.00 ( 13.09)\n",
      "Epoch: [0][1150/2503]\tTime  1.859 ( 1.313)\tData  0.000 ( 0.020)\tLoss 4.8974e+00 (5.7018e+00)\tAcc@1   7.42 (  4.80)\tAcc@5  26.17 ( 13.60)\n",
      "Epoch: [0][1200/2503]\tTime  1.880 ( 1.316)\tData  0.000 ( 0.020)\tLoss 5.0918e+00 (5.6683e+00)\tAcc@1  10.16 (  5.02)\tAcc@5  25.00 ( 14.10)\n",
      "Epoch: [0][1250/2503]\tTime  1.477 ( 1.318)\tData  0.000 ( 0.020)\tLoss 5.0531e+00 (5.6365e+00)\tAcc@1   8.20 (  5.25)\tAcc@5  24.61 ( 14.61)\n",
      "Epoch: [0][1300/2503]\tTime  1.552 ( 1.321)\tData  0.000 ( 0.020)\tLoss 4.7138e+00 (5.6041e+00)\tAcc@1  12.11 (  5.48)\tAcc@5  27.34 ( 15.13)\n",
      "Epoch: [0][1350/2503]\tTime  1.254 ( 1.323)\tData  0.000 ( 0.020)\tLoss 4.7404e+00 (5.5740e+00)\tAcc@1   9.77 (  5.70)\tAcc@5  28.91 ( 15.60)\n",
      "Epoch: [0][1400/2503]\tTime  1.345 ( 1.325)\tData  0.000 ( 0.020)\tLoss 4.8368e+00 (5.5427e+00)\tAcc@1   9.77 (  5.94)\tAcc@5  25.00 ( 16.08)\n",
      "Epoch: [0][1450/2503]\tTime  1.563 ( 1.327)\tData  0.000 ( 0.020)\tLoss 4.6594e+00 (5.5138e+00)\tAcc@1  10.94 (  6.15)\tAcc@5  27.73 ( 16.53)\n",
      "Epoch: [0][1500/2503]\tTime  1.499 ( 1.329)\tData  0.000 ( 0.020)\tLoss 4.4237e+00 (5.4866e+00)\tAcc@1  12.89 (  6.36)\tAcc@5  31.25 ( 16.95)\n",
      "Epoch: [0][1550/2503]\tTime  1.214 ( 1.330)\tData  0.000 ( 0.020)\tLoss 4.8106e+00 (5.4588e+00)\tAcc@1  10.55 (  6.57)\tAcc@5  26.95 ( 17.38)\n",
      "Epoch: [0][1600/2503]\tTime  1.176 ( 1.331)\tData  0.000 ( 0.020)\tLoss 4.6065e+00 (5.4306e+00)\tAcc@1  11.33 (  6.79)\tAcc@5  26.95 ( 17.84)\n",
      "Epoch: [0][1650/2503]\tTime  1.058 ( 1.333)\tData  0.000 ( 0.020)\tLoss 4.4616e+00 (5.4036e+00)\tAcc@1  15.62 (  7.02)\tAcc@5  36.33 ( 18.29)\n",
      "Epoch: [0][1700/2503]\tTime  1.295 ( 1.335)\tData  0.000 ( 0.020)\tLoss 4.6101e+00 (5.3764e+00)\tAcc@1  12.89 (  7.23)\tAcc@5  32.03 ( 18.74)\n",
      "Epoch: [0][1750/2503]\tTime  1.674 ( 1.337)\tData  0.000 ( 0.020)\tLoss 4.6714e+00 (5.3509e+00)\tAcc@1  14.84 (  7.45)\tAcc@5  32.03 ( 19.17)\n",
      "Epoch: [0][1800/2503]\tTime  2.267 ( 1.338)\tData  0.001 ( 0.020)\tLoss 4.2430e+00 (5.3252e+00)\tAcc@1  18.75 (  7.68)\tAcc@5  35.94 ( 19.61)\n",
      "Epoch: [0][1850/2503]\tTime  0.982 ( 1.339)\tData  0.000 ( 0.019)\tLoss 4.4380e+00 (5.3007e+00)\tAcc@1  12.11 (  7.89)\tAcc@5  30.86 ( 20.01)\n",
      "Epoch: [0][1900/2503]\tTime  2.157 ( 1.340)\tData  0.000 ( 0.020)\tLoss 4.5744e+00 (5.2770e+00)\tAcc@1  15.62 (  8.09)\tAcc@5  32.81 ( 20.40)\n",
      "Epoch: [0][1950/2503]\tTime  1.216 ( 1.341)\tData  0.000 ( 0.020)\tLoss 4.3716e+00 (5.2537e+00)\tAcc@1  17.97 (  8.30)\tAcc@5  35.55 ( 20.80)\n",
      "Epoch: [0][2000/2503]\tTime  1.162 ( 1.342)\tData  0.000 ( 0.020)\tLoss 4.4065e+00 (5.2308e+00)\tAcc@1  14.06 (  8.51)\tAcc@5  35.94 ( 21.17)\n",
      "Epoch: [0][2050/2503]\tTime  1.232 ( 1.343)\tData  0.000 ( 0.020)\tLoss 4.2642e+00 (5.2087e+00)\tAcc@1  18.36 (  8.70)\tAcc@5  37.50 ( 21.55)\n",
      "Epoch: [0][2100/2503]\tTime  1.232 ( 1.344)\tData  0.000 ( 0.020)\tLoss 4.3311e+00 (5.1867e+00)\tAcc@1  14.84 (  8.90)\tAcc@5  36.72 ( 21.92)\n",
      "Epoch: [0][2150/2503]\tTime  1.278 ( 1.345)\tData  0.000 ( 0.019)\tLoss 4.3788e+00 (5.1650e+00)\tAcc@1  17.19 (  9.10)\tAcc@5  38.28 ( 22.30)\n",
      "Epoch: [0][2200/2503]\tTime  1.378 ( 1.346)\tData  0.000 ( 0.019)\tLoss 4.4787e+00 (5.1434e+00)\tAcc@1  14.84 (  9.31)\tAcc@5  32.81 ( 22.67)\n",
      "Epoch: [0][2250/2503]\tTime  1.399 ( 1.347)\tData  0.000 ( 0.019)\tLoss 4.1600e+00 (5.1217e+00)\tAcc@1  17.97 (  9.52)\tAcc@5  38.28 ( 23.03)\n",
      "Epoch: [0][2300/2503]\tTime  0.988 ( 1.348)\tData  0.000 ( 0.019)\tLoss 4.3102e+00 (5.0999e+00)\tAcc@1  17.19 (  9.72)\tAcc@5  35.55 ( 23.40)\n",
      "Epoch: [0][2350/2503]\tTime  1.333 ( 1.349)\tData  0.000 ( 0.019)\tLoss 4.2590e+00 (5.0791e+00)\tAcc@1  17.97 (  9.93)\tAcc@5  37.50 ( 23.77)\n",
      "Epoch: [0][2400/2503]\tTime  1.217 ( 1.350)\tData  0.000 ( 0.019)\tLoss 3.9617e+00 (5.0592e+00)\tAcc@1  19.53 ( 10.13)\tAcc@5  40.23 ( 24.12)\n",
      "Epoch: [0][2450/2503]\tTime  1.144 ( 1.351)\tData  0.000 ( 0.019)\tLoss 4.1177e+00 (5.0392e+00)\tAcc@1  17.97 ( 10.31)\tAcc@5  38.67 ( 24.47)\n",
      "Epoch: [0][2500/2503]\tTime  1.296 ( 1.352)\tData  0.000 ( 0.019)\tLoss 4.0925e+00 (5.0196e+00)\tAcc@1  21.09 ( 10.50)\tAcc@5  40.62 ( 24.81)\n",
      "Test: [  0/196]\tTime  3.336 ( 3.336)\tLoss 3.1106e+00 (3.1106e+00)\tAcc@1  30.86 ( 30.86)\tAcc@5  67.58 ( 67.58)\n",
      "Test: [ 50/196]\tTime  0.387 ( 0.421)\tLoss 3.6521e+00 (3.7618e+00)\tAcc@1  25.39 ( 21.15)\tAcc@5  46.48 ( 46.58)\n",
      "Test: [100/196]\tTime  0.378 ( 0.409)\tLoss 5.5246e+00 (3.9922e+00)\tAcc@1   3.91 ( 19.50)\tAcc@5  10.55 ( 42.61)\n",
      "Test: [150/196]\tTime  0.584 ( 0.405)\tLoss 4.8441e+00 (4.1059e+00)\tAcc@1  14.45 ( 18.47)\tAcc@5  26.56 ( 40.52)\n",
      " * Acc@1 18.550 Acc@5 40.284\n",
      "lr: [0.09999383162408304]\n",
      "Epoch Time: 57.753222771485646 minutes\n",
      "Epoch: [1][   0/2503]\tTime  3.384 ( 3.384)\tData  3.075 ( 3.075)\tLoss 3.8111e+00 (3.8111e+00)\tAcc@1  21.48 ( 21.48)\tAcc@5  46.48 ( 46.48)\n"
     ]
    }
   ],
   "source": [
    "best_acc1 = 0\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    #Implement Learning Rate Adjustment\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "    wandb.log({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    })\n",
    "    \n",
    "    t2 = time.time()\n",
    "    \n",
    "    print(\"Epoch Time:\",(t2-t1)/60,\"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d6ed4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
