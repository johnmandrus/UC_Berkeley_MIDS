{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d70590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae207751",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ab1fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "169ea4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 0\n",
    "ARCH = 'resnet18'\n",
    "EPOCHS = 200\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=256\n",
    "VAL_BATCH=256\n",
    "WORKERS=8\n",
    "TRAINDIR=\"/workspace/storage/train\"\n",
    "VALDIR=\"/workspace/storage/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75005ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bf22c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eed45a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'tcp://3.19.70.152:1234'\n",
    "BACKEND = 'nccl'\n",
    "WORLD_SIZE = 2\n",
    "RANK = 1\n",
    "\n",
    "dist.init_process_group(backend = BACKEND, init_method= URL,\n",
    "                                 world_size= WORLD_SIZE, rank=RANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3cb189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = 0\n",
    "torch.cuda.set_device(GPU)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d8aa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84914aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d771a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e43a6fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae165b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed749e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    #lr = LR * (0.1 ** (epoch // 30))\n",
    "    lr = LR * (0.1 ** (epoch // 17))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8482ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "773f0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1472c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=imagenet_mean_RGB, std=imagenet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e66c27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 1000\n",
    "model = models.__dict__[ARCH]()\n",
    "inf = model.fc.in_features\n",
    "model.fc = nn.Linear(inf, NUM_CLASSES)\n",
    "model.cuda(GPU)\n",
    "model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[GPU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29d6a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)\n",
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb3d41a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = datasets.ImageFolder(\n",
    "#     TRAINDIR, transform=transform_train)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a3709ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform_val = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "# ])\n",
    "\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a56cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=torch.utils.data.distributed.DistributedSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1144096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37b398ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/2503]\tTime 17.952 (17.952)\tData  3.847 ( 3.847)\tLoss 7.0251e+00 (7.0251e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.39 (  0.39)\n",
      "Epoch: [0][  50/2503]\tTime  0.786 ( 1.099)\tData  0.000 ( 0.080)\tLoss 6.7423e+00 (6.9377e+00)\tAcc@1   0.78 (  0.21)\tAcc@5   3.52 (  1.02)\n",
      "Epoch: [0][ 100/2503]\tTime  0.814 ( 0.952)\tData  0.000 ( 0.046)\tLoss 6.6297e+00 (6.8077e+00)\tAcc@1   0.39 (  0.47)\tAcc@5   3.12 (  1.83)\n",
      "Epoch: [0][ 150/2503]\tTime  1.699 ( 0.989)\tData  0.000 ( 0.035)\tLoss 6.5039e+00 (6.7087e+00)\tAcc@1   0.78 (  0.65)\tAcc@5   3.52 (  2.48)\n",
      "Epoch: [0][ 200/2503]\tTime  1.589 ( 1.071)\tData  0.000 ( 0.031)\tLoss 6.4395e+00 (6.6247e+00)\tAcc@1   0.00 (  0.85)\tAcc@5   3.12 (  3.12)\n",
      "Epoch: [0][ 250/2503]\tTime  1.330 ( 1.132)\tData  0.000 ( 0.028)\tLoss 6.2302e+00 (6.5439e+00)\tAcc@1   0.78 (  1.04)\tAcc@5   5.86 (  3.73)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 300/2503]\tTime  1.275 ( 1.166)\tData  0.000 ( 0.027)\tLoss 6.1233e+00 (6.4709e+00)\tAcc@1   2.34 (  1.21)\tAcc@5   5.47 (  4.32)\n",
      "Epoch: [0][ 350/2503]\tTime  1.226 ( 1.196)\tData  0.000 ( 0.026)\tLoss 6.1139e+00 (6.4073e+00)\tAcc@1   2.34 (  1.40)\tAcc@5   7.03 (  4.86)\n",
      "Epoch: [0][ 400/2503]\tTime  1.184 ( 1.218)\tData  0.000 ( 0.026)\tLoss 5.7536e+00 (6.3457e+00)\tAcc@1   4.30 (  1.57)\tAcc@5  11.33 (  5.40)\n",
      "Epoch: [0][ 450/2503]\tTime  1.263 ( 1.235)\tData  0.000 ( 0.025)\tLoss 5.8076e+00 (6.2892e+00)\tAcc@1   1.56 (  1.77)\tAcc@5   8.59 (  6.00)\n",
      "Epoch: [0][ 500/2503]\tTime  1.046 ( 1.248)\tData  0.000 ( 0.025)\tLoss 5.7697e+00 (6.2324e+00)\tAcc@1   2.34 (  1.95)\tAcc@5  10.55 (  6.62)\n",
      "Epoch: [0][ 550/2503]\tTime  1.312 ( 1.259)\tData  0.000 ( 0.024)\tLoss 5.6152e+00 (6.1797e+00)\tAcc@1   5.86 (  2.19)\tAcc@5  14.06 (  7.21)\n",
      "Epoch: [0][ 600/2503]\tTime  1.700 ( 1.268)\tData  0.000 ( 0.024)\tLoss 5.5690e+00 (6.1310e+00)\tAcc@1   3.52 (  2.39)\tAcc@5  11.72 (  7.80)\n",
      "Epoch: [0][ 650/2503]\tTime  1.842 ( 1.277)\tData  0.000 ( 0.024)\tLoss 5.4820e+00 (6.0837e+00)\tAcc@1   6.25 (  2.57)\tAcc@5  16.80 (  8.36)\n",
      "Epoch: [0][ 700/2503]\tTime  1.275 ( 1.283)\tData  0.000 ( 0.023)\tLoss 5.5885e+00 (6.0366e+00)\tAcc@1   7.42 (  2.81)\tAcc@5  13.28 (  8.92)\n",
      "Epoch: [0][ 750/2503]\tTime  1.195 ( 1.288)\tData  0.000 ( 0.023)\tLoss 5.2063e+00 (5.9926e+00)\tAcc@1   8.20 (  3.04)\tAcc@5  18.36 (  9.49)\n",
      "Epoch: [0][ 800/2503]\tTime  1.205 ( 1.294)\tData  0.000 ( 0.024)\tLoss 5.4581e+00 (5.9529e+00)\tAcc@1   3.91 (  3.22)\tAcc@5  14.45 ( 10.01)\n",
      "Epoch: [0][ 850/2503]\tTime  1.129 ( 1.299)\tData  0.000 ( 0.024)\tLoss 5.3445e+00 (5.9116e+00)\tAcc@1   8.20 (  3.44)\tAcc@5  18.36 ( 10.58)\n",
      "Epoch: [0][ 900/2503]\tTime  1.023 ( 1.302)\tData  0.000 ( 0.024)\tLoss 5.2376e+00 (5.8753e+00)\tAcc@1   7.03 (  3.65)\tAcc@5  19.92 ( 11.07)\n",
      "Epoch: [0][ 950/2503]\tTime  1.666 ( 1.306)\tData  0.000 ( 0.024)\tLoss 5.1251e+00 (5.8382e+00)\tAcc@1   8.59 (  3.86)\tAcc@5  23.05 ( 11.60)\n",
      "Epoch: [0][1000/2503]\tTime  1.593 ( 1.309)\tData  0.000 ( 0.024)\tLoss 5.0818e+00 (5.8031e+00)\tAcc@1  10.16 (  4.09)\tAcc@5  24.22 ( 12.12)\n",
      "Epoch: [0][1050/2503]\tTime  1.156 ( 1.312)\tData  0.000 ( 0.024)\tLoss 5.1846e+00 (5.7684e+00)\tAcc@1   6.25 (  4.29)\tAcc@5  19.53 ( 12.60)\n",
      "Epoch: [0][1100/2503]\tTime  1.148 ( 1.315)\tData  0.000 ( 0.023)\tLoss 5.0502e+00 (5.7338e+00)\tAcc@1  11.33 (  4.52)\tAcc@5  24.61 ( 13.10)\n",
      "Epoch: [0][1150/2503]\tTime  1.565 ( 1.318)\tData  0.000 ( 0.024)\tLoss 4.9543e+00 (5.6996e+00)\tAcc@1  10.55 (  4.73)\tAcc@5  21.09 ( 13.60)\n",
      "Epoch: [0][1200/2503]\tTime  1.851 ( 1.320)\tData  0.000 ( 0.024)\tLoss 4.7817e+00 (5.6676e+00)\tAcc@1  12.50 (  4.95)\tAcc@5  26.95 ( 14.06)\n",
      "Epoch: [0][1250/2503]\tTime  1.255 ( 1.322)\tData  0.000 ( 0.024)\tLoss 5.0173e+00 (5.6352e+00)\tAcc@1   7.81 (  5.17)\tAcc@5  23.83 ( 14.58)\n",
      "Epoch: [0][1300/2503]\tTime  1.309 ( 1.325)\tData  0.000 ( 0.024)\tLoss 4.6118e+00 (5.6037e+00)\tAcc@1  14.84 (  5.39)\tAcc@5  32.81 ( 15.07)\n",
      "Epoch: [0][1350/2503]\tTime  1.299 ( 1.327)\tData  0.000 ( 0.024)\tLoss 4.8649e+00 (5.5732e+00)\tAcc@1  12.11 (  5.60)\tAcc@5  24.22 ( 15.54)\n",
      "Epoch: [0][1400/2503]\tTime  1.339 ( 1.329)\tData  0.000 ( 0.024)\tLoss 4.7926e+00 (5.5435e+00)\tAcc@1   8.59 (  5.82)\tAcc@5  26.56 ( 16.00)\n",
      "Epoch: [0][1450/2503]\tTime  1.527 ( 1.330)\tData  0.000 ( 0.024)\tLoss 4.6770e+00 (5.5140e+00)\tAcc@1  13.67 (  6.04)\tAcc@5  28.12 ( 16.47)\n",
      "Epoch: [0][1500/2503]\tTime  1.331 ( 1.332)\tData  0.000 ( 0.024)\tLoss 4.4257e+00 (5.4851e+00)\tAcc@1  14.45 (  6.28)\tAcc@5  35.55 ( 16.94)\n",
      "Epoch: [0][1550/2503]\tTime  1.213 ( 1.333)\tData  0.000 ( 0.024)\tLoss 4.7368e+00 (5.4573e+00)\tAcc@1  11.33 (  6.51)\tAcc@5  28.52 ( 17.42)\n",
      "Epoch: [0][1600/2503]\tTime  1.181 ( 1.335)\tData  0.000 ( 0.024)\tLoss 4.6643e+00 (5.4297e+00)\tAcc@1  13.28 (  6.72)\tAcc@5  31.25 ( 17.87)\n",
      "Epoch: [0][1650/2503]\tTime  0.984 ( 1.336)\tData  0.000 ( 0.024)\tLoss 4.4641e+00 (5.4034e+00)\tAcc@1  17.97 (  6.95)\tAcc@5  34.38 ( 18.30)\n",
      "Epoch: [0][1700/2503]\tTime  1.292 ( 1.338)\tData  0.000 ( 0.024)\tLoss 4.5220e+00 (5.3770e+00)\tAcc@1  12.50 (  7.17)\tAcc@5  31.64 ( 18.73)\n",
      "Epoch: [0][1750/2503]\tTime  1.545 ( 1.339)\tData  0.000 ( 0.024)\tLoss 4.4125e+00 (5.3512e+00)\tAcc@1  16.80 (  7.38)\tAcc@5  35.55 ( 19.16)\n",
      "Epoch: [0][1800/2503]\tTime  1.720 ( 1.341)\tData  0.000 ( 0.024)\tLoss 4.2561e+00 (5.3263e+00)\tAcc@1  18.75 (  7.58)\tAcc@5  38.67 ( 19.57)\n",
      "Epoch: [0][1850/2503]\tTime  0.993 ( 1.342)\tData  0.000 ( 0.024)\tLoss 4.3151e+00 (5.3023e+00)\tAcc@1  16.80 (  7.79)\tAcc@5  38.28 ( 19.97)\n",
      "Epoch: [0][1900/2503]\tTime  1.912 ( 1.343)\tData  0.000 ( 0.024)\tLoss 4.2140e+00 (5.2776e+00)\tAcc@1  16.80 (  8.01)\tAcc@5  37.89 ( 20.39)\n",
      "Epoch: [0][1950/2503]\tTime  1.268 ( 1.344)\tData  0.000 ( 0.024)\tLoss 4.3459e+00 (5.2540e+00)\tAcc@1  16.02 (  8.23)\tAcc@5  35.94 ( 20.79)\n",
      "Epoch: [0][2000/2503]\tTime  1.077 ( 1.345)\tData  0.000 ( 0.024)\tLoss 4.3130e+00 (5.2316e+00)\tAcc@1  14.45 (  8.42)\tAcc@5  35.94 ( 21.17)\n",
      "Epoch: [0][2050/2503]\tTime  1.228 ( 1.346)\tData  0.000 ( 0.024)\tLoss 4.2341e+00 (5.2085e+00)\tAcc@1  17.58 (  8.64)\tAcc@5  38.67 ( 21.57)\n",
      "Epoch: [0][2100/2503]\tTime  1.231 ( 1.347)\tData  0.000 ( 0.024)\tLoss 4.1950e+00 (5.1860e+00)\tAcc@1  17.97 (  8.84)\tAcc@5  39.84 ( 21.95)\n",
      "Epoch: [0][2150/2503]\tTime  1.281 ( 1.348)\tData  0.000 ( 0.024)\tLoss 4.4579e+00 (5.1639e+00)\tAcc@1  11.33 (  9.05)\tAcc@5  33.98 ( 22.34)\n",
      "Epoch: [0][2200/2503]\tTime  1.808 ( 1.349)\tData  0.000 ( 0.024)\tLoss 4.4225e+00 (5.1428e+00)\tAcc@1  16.80 (  9.25)\tAcc@5  33.59 ( 22.69)\n",
      "Epoch: [0][2250/2503]\tTime  1.096 ( 1.349)\tData  0.000 ( 0.023)\tLoss 4.3644e+00 (5.1211e+00)\tAcc@1  14.84 (  9.45)\tAcc@5  36.33 ( 23.08)\n",
      "Epoch: [0][2300/2503]\tTime  1.554 ( 1.351)\tData  0.000 ( 0.024)\tLoss 4.0106e+00 (5.1003e+00)\tAcc@1  19.53 (  9.65)\tAcc@5  36.33 ( 23.43)\n",
      "Epoch: [0][2350/2503]\tTime  1.391 ( 1.352)\tData  0.000 ( 0.023)\tLoss 4.0515e+00 (5.0794e+00)\tAcc@1  18.75 (  9.85)\tAcc@5  37.50 ( 23.79)\n",
      "Epoch: [0][2400/2503]\tTime  1.189 ( 1.352)\tData  0.000 ( 0.023)\tLoss 4.1043e+00 (5.0583e+00)\tAcc@1  20.31 ( 10.06)\tAcc@5  39.45 ( 24.15)\n",
      "Epoch: [0][2450/2503]\tTime  1.709 ( 1.353)\tData  0.001 ( 0.023)\tLoss 4.0395e+00 (5.0390e+00)\tAcc@1  21.09 ( 10.24)\tAcc@5  43.75 ( 24.48)\n",
      "Epoch: [0][2500/2503]\tTime  1.298 ( 1.354)\tData  0.000 ( 0.023)\tLoss 3.9100e+00 (5.0193e+00)\tAcc@1  21.09 ( 10.44)\tAcc@5  45.31 ( 24.83)\n",
      "Test: [  0/196]\tTime  4.284 ( 4.284)\tLoss 3.1106e+00 (3.1106e+00)\tAcc@1  30.86 ( 30.86)\tAcc@5  67.58 ( 67.58)\n",
      "Test: [ 50/196]\tTime  0.206 ( 0.344)\tLoss 3.6521e+00 (3.7618e+00)\tAcc@1  25.39 ( 21.15)\tAcc@5  46.48 ( 46.58)\n",
      "Test: [100/196]\tTime  0.205 ( 0.317)\tLoss 5.5246e+00 (3.9922e+00)\tAcc@1   3.91 ( 19.50)\tAcc@5  10.55 ( 42.61)\n",
      "Test: [150/196]\tTime  0.251 ( 0.308)\tLoss 4.8440e+00 (4.1059e+00)\tAcc@1  14.45 ( 18.47)\tAcc@5  26.56 ( 40.52)\n",
      " * Acc@1 18.550 Acc@5 40.284\n",
      "lr: [0.09999383162408304]\n",
      "Epoch Time: 57.47829018036524 minutes\n",
      "Epoch: [1][   0/2503]\tTime  3.510 ( 3.510)\tData  3.186 ( 3.186)\tLoss 4.1079e+00 (4.1079e+00)\tAcc@1  17.19 ( 17.19)\tAcc@5  44.53 ( 44.53)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9bdc9689de26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-abc104badad0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# measure accuracy and record loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0macc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mtop1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtop5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc1 = 0\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    #Implement Learning Rate Adjustment\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "    t2 = time.time()\n",
    "    \n",
    "    print(\"Epoch Time:\",(t2-t1)/60,\"minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
