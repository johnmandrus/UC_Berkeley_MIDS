{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "587b5962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dbc598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cf8bbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56030d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 0\n",
    "ARCH = 'resnet18'\n",
    "EPOCHS = 200\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=256\n",
    "VAL_BATCH=256\n",
    "WORKERS=8\n",
    "TRAINDIR=\"/workspace/storage/train\"\n",
    "VALDIR=\"/workspace/storage/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "139d273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbeb9f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'tcp://3.19.70.152:1234'\n",
    "BACKEND = 'nccl'\n",
    "WORLD_SIZE = 1\n",
    "RANK = 0\n",
    "\n",
    "dist.init_process_group(backend = BACKEND, init_method= URL,\n",
    "                                 world_size= WORLD_SIZE, rank=RANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "805ee485",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = 0\n",
    "torch.cuda.set_device(GPU)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "620d19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15f3eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "680ba951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd2352b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "413ddef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc74c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    #lr = LR * (0.1 ** (epoch // 30))\n",
    "    lr = LR * (0.1 ** (epoch // 17))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6eb4a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0b78bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a8b94d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=imagenet_mean_RGB, std=imagenet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3385ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 1000\n",
    "#model = models.resnet18()\n",
    "model = models.__dict__[ARCH]()\n",
    "inf = model.fc.in_features\n",
    "model.fc = nn.Linear(inf, NUM_CLASSES)\n",
    "model.cuda(GPU)\n",
    "model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[GPU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df96ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)\n",
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53b8fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = datasets.ImageFolder(\n",
    "#     TRAINDIR, transform=transform_train)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a083228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform_val = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "# ])\n",
    "\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "389b58f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=torch.utils.data.distributed.DistributedSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0de78d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e237be40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install -q wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7080cd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjohnmandrus\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">northern-snowflake-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/johnmandrus/john-andrus-HW9-1node\" target=\"_blank\">https://wandb.ai/johnmandrus/john-andrus-HW9-1node</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/johnmandrus/john-andrus-HW9-1node/runs/1hegeo1y\" target=\"_blank\">https://wandb.ai/johnmandrus/john-andrus-HW9-1node/runs/1hegeo1y</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/storage/wandb/run-20210707_213258-1hegeo1y</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(1hegeo1y)</h1><iframe src=\"https://wandb.ai/johnmandrus/john-andrus-HW9-1node/runs/1hegeo1y\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f145d63bb50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"john-andrus-HW9-1node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d53f456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/5005]\tTime 10.354 (10.354)\tData  3.641 ( 3.641)\tLoss 6.9477e+00 (6.9477e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   1.95 (  1.95)\n",
      "Epoch: [0][  50/5005]\tTime  0.773 ( 0.943)\tData  0.000 ( 0.072)\tLoss 6.8990e+00 (7.0538e+00)\tAcc@1   0.39 (  0.22)\tAcc@5   1.17 (  0.86)\n",
      "Epoch: [0][ 100/5005]\tTime  0.826 ( 0.874)\tData  0.000 ( 0.042)\tLoss 6.7530e+00 (6.9402e+00)\tAcc@1   1.56 (  0.33)\tAcc@5   3.91 (  1.27)\n",
      "Epoch: [0][ 150/5005]\tTime  1.336 ( 0.968)\tData  0.000 ( 0.032)\tLoss 6.6977e+00 (6.8640e+00)\tAcc@1   0.00 (  0.44)\tAcc@5   2.73 (  1.65)\n",
      "Epoch: [0][ 200/5005]\tTime  1.329 ( 1.059)\tData  0.000 ( 0.028)\tLoss 6.6168e+00 (6.8077e+00)\tAcc@1   0.78 (  0.48)\tAcc@5   3.52 (  1.88)\n",
      "Epoch: [0][ 250/5005]\tTime  1.332 ( 1.124)\tData  0.000 ( 0.026)\tLoss 6.5420e+00 (6.7567e+00)\tAcc@1   1.56 (  0.55)\tAcc@5   4.30 (  2.14)\n",
      "Epoch: [0][ 300/5005]\tTime  1.344 ( 1.163)\tData  0.000 ( 0.025)\tLoss 6.4127e+00 (6.7094e+00)\tAcc@1   1.17 (  0.62)\tAcc@5   4.69 (  2.45)\n",
      "Epoch: [0][ 350/5005]\tTime  1.285 ( 1.196)\tData  0.000 ( 0.024)\tLoss 6.3360e+00 (6.6639e+00)\tAcc@1   3.12 (  0.71)\tAcc@5   6.25 (  2.78)\n",
      "Epoch: [0][ 400/5005]\tTime  1.017 ( 1.222)\tData  0.000 ( 0.023)\tLoss 6.3312e+00 (6.6215e+00)\tAcc@1   1.17 (  0.81)\tAcc@5   5.08 (  3.04)\n",
      "Epoch: [0][ 450/5005]\tTime  1.303 ( 1.240)\tData  0.000 ( 0.023)\tLoss 6.1989e+00 (6.5803e+00)\tAcc@1   2.73 (  0.89)\tAcc@5   7.42 (  3.34)\n",
      "Epoch: [0][ 500/5005]\tTime  1.334 ( 1.254)\tData  0.000 ( 0.022)\tLoss 6.1995e+00 (6.5428e+00)\tAcc@1   1.17 (  0.97)\tAcc@5   4.69 (  3.60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 550/5005]\tTime  1.277 ( 1.267)\tData  0.000 ( 0.022)\tLoss 6.0636e+00 (6.5066e+00)\tAcc@1   1.17 (  1.03)\tAcc@5   5.08 (  3.88)\n",
      "Epoch: [0][ 600/5005]\tTime  1.403 ( 1.279)\tData  0.000 ( 0.022)\tLoss 6.0621e+00 (6.4690e+00)\tAcc@1   2.34 (  1.14)\tAcc@5   7.42 (  4.22)\n",
      "Epoch: [0][ 650/5005]\tTime  1.347 ( 1.288)\tData  0.000 ( 0.021)\tLoss 6.0173e+00 (6.4347e+00)\tAcc@1   1.95 (  1.24)\tAcc@5   8.59 (  4.54)\n",
      "Epoch: [0][ 700/5005]\tTime  1.275 ( 1.295)\tData  0.000 ( 0.021)\tLoss 6.0002e+00 (6.4007e+00)\tAcc@1   4.69 (  1.34)\tAcc@5  10.55 (  4.85)\n",
      "Epoch: [0][ 750/5005]\tTime  2.294 ( 1.304)\tData  0.000 ( 0.021)\tLoss 5.9593e+00 (6.3690e+00)\tAcc@1   2.73 (  1.46)\tAcc@5  10.94 (  5.17)\n",
      "Epoch: [0][ 800/5005]\tTime  1.449 ( 1.309)\tData  0.000 ( 0.021)\tLoss 5.8184e+00 (6.3371e+00)\tAcc@1   4.69 (  1.56)\tAcc@5  12.50 (  5.48)\n",
      "Epoch: [0][ 850/5005]\tTime  1.335 ( 1.315)\tData  0.000 ( 0.021)\tLoss 5.7869e+00 (6.3070e+00)\tAcc@1   2.73 (  1.67)\tAcc@5   9.77 (  5.79)\n",
      "Epoch: [0][ 900/5005]\tTime  1.334 ( 1.318)\tData  0.000 ( 0.021)\tLoss 5.6800e+00 (6.2776e+00)\tAcc@1   4.30 (  1.77)\tAcc@5  11.72 (  6.11)\n",
      "Epoch: [0][ 950/5005]\tTime  1.918 ( 1.323)\tData  0.000 ( 0.021)\tLoss 5.7439e+00 (6.2483e+00)\tAcc@1   3.91 (  1.88)\tAcc@5  11.33 (  6.42)\n",
      "Epoch: [0][1000/5005]\tTime  1.304 ( 1.326)\tData  0.000 ( 0.020)\tLoss 5.8008e+00 (6.2185e+00)\tAcc@1   3.12 (  2.00)\tAcc@5  11.72 (  6.74)\n",
      "Epoch: [0][1050/5005]\tTime  1.773 ( 1.330)\tData  0.000 ( 0.020)\tLoss 5.5780e+00 (6.1899e+00)\tAcc@1   7.81 (  2.13)\tAcc@5  15.62 (  7.08)\n",
      "Epoch: [0][1100/5005]\tTime  1.284 ( 1.332)\tData  0.000 ( 0.020)\tLoss 5.4858e+00 (6.1624e+00)\tAcc@1   4.69 (  2.25)\tAcc@5  16.80 (  7.41)\n",
      "Epoch: [0][1150/5005]\tTime  1.199 ( 1.334)\tData  0.000 ( 0.020)\tLoss 5.5547e+00 (6.1355e+00)\tAcc@1   5.08 (  2.37)\tAcc@5  16.80 (  7.74)\n",
      "Epoch: [0][1200/5005]\tTime  1.651 ( 1.337)\tData  0.000 ( 0.020)\tLoss 5.5098e+00 (6.1078e+00)\tAcc@1   3.52 (  2.49)\tAcc@5  12.11 (  8.08)\n",
      "Epoch: [0][1250/5005]\tTime  1.117 ( 1.339)\tData  0.000 ( 0.020)\tLoss 5.4819e+00 (6.0824e+00)\tAcc@1   5.47 (  2.61)\tAcc@5  17.58 (  8.40)\n",
      "Epoch: [0][1300/5005]\tTime  1.744 ( 1.342)\tData  0.000 ( 0.020)\tLoss 5.5375e+00 (6.0570e+00)\tAcc@1   7.42 (  2.74)\tAcc@5  17.19 (  8.71)\n",
      "Epoch: [0][1350/5005]\tTime  1.213 ( 1.343)\tData  0.000 ( 0.020)\tLoss 5.4087e+00 (6.0317e+00)\tAcc@1   5.08 (  2.86)\tAcc@5  16.41 (  9.03)\n",
      "Epoch: [0][1400/5005]\tTime  2.388 ( 1.345)\tData  0.000 ( 0.019)\tLoss 5.3688e+00 (6.0068e+00)\tAcc@1   6.64 (  2.98)\tAcc@5  21.09 (  9.34)\n",
      "Epoch: [0][1450/5005]\tTime  1.315 ( 1.346)\tData  0.000 ( 0.019)\tLoss 5.1472e+00 (5.9841e+00)\tAcc@1   7.42 (  3.10)\tAcc@5  19.53 (  9.63)\n",
      "Epoch: [0][1500/5005]\tTime  1.324 ( 1.348)\tData  0.000 ( 0.019)\tLoss 5.3401e+00 (5.9608e+00)\tAcc@1   5.47 (  3.21)\tAcc@5  15.23 (  9.93)\n",
      "Epoch: [0][1550/5005]\tTime  1.337 ( 1.350)\tData  0.000 ( 0.019)\tLoss 5.3843e+00 (5.9390e+00)\tAcc@1   6.25 (  3.33)\tAcc@5  19.53 ( 10.24)\n",
      "Epoch: [0][1600/5005]\tTime  1.148 ( 1.352)\tData  0.000 ( 0.019)\tLoss 5.0845e+00 (5.9169e+00)\tAcc@1   7.03 (  3.44)\tAcc@5  22.27 ( 10.54)\n",
      "Epoch: [0][1650/5005]\tTime  1.070 ( 1.353)\tData  0.000 ( 0.020)\tLoss 5.2722e+00 (5.8947e+00)\tAcc@1   6.25 (  3.56)\tAcc@5  20.31 ( 10.85)\n",
      "Epoch: [0][1700/5005]\tTime  1.040 ( 1.355)\tData  0.000 ( 0.019)\tLoss 4.9793e+00 (5.8728e+00)\tAcc@1  10.94 (  3.69)\tAcc@5  24.61 ( 11.17)\n",
      "Epoch: [0][1750/5005]\tTime  1.279 ( 1.356)\tData  0.000 ( 0.019)\tLoss 4.9905e+00 (5.8524e+00)\tAcc@1   8.98 (  3.81)\tAcc@5  23.44 ( 11.46)\n",
      "Epoch: [0][1800/5005]\tTime  1.705 ( 1.356)\tData  0.000 ( 0.019)\tLoss 5.0783e+00 (5.8320e+00)\tAcc@1   8.59 (  3.93)\tAcc@5  23.05 ( 11.74)\n",
      "Epoch: [0][1850/5005]\tTime  1.085 ( 1.357)\tData  0.000 ( 0.019)\tLoss 5.1407e+00 (5.8117e+00)\tAcc@1   9.38 (  4.06)\tAcc@5  19.14 ( 12.02)\n",
      "Epoch: [0][1900/5005]\tTime  1.155 ( 1.359)\tData  0.000 ( 0.020)\tLoss 5.0446e+00 (5.7912e+00)\tAcc@1  10.16 (  4.18)\tAcc@5  24.22 ( 12.33)\n",
      "Epoch: [0][1950/5005]\tTime  1.387 ( 1.360)\tData  0.000 ( 0.020)\tLoss 4.8774e+00 (5.7714e+00)\tAcc@1   7.81 (  4.31)\tAcc@5  23.05 ( 12.61)\n",
      "Epoch: [0][2000/5005]\tTime  1.215 ( 1.360)\tData  0.000 ( 0.020)\tLoss 5.0298e+00 (5.7523e+00)\tAcc@1   8.98 (  4.43)\tAcc@5  25.00 ( 12.88)\n",
      "Epoch: [0][2050/5005]\tTime  1.725 ( 1.362)\tData  0.000 ( 0.020)\tLoss 4.9856e+00 (5.7331e+00)\tAcc@1   8.98 (  4.55)\tAcc@5  22.27 ( 13.16)\n",
      "Epoch: [0][2100/5005]\tTime  1.118 ( 1.362)\tData  0.000 ( 0.020)\tLoss 4.9893e+00 (5.7143e+00)\tAcc@1   8.98 (  4.67)\tAcc@5  21.09 ( 13.43)\n",
      "Epoch: [0][2150/5005]\tTime  2.257 ( 1.363)\tData  0.000 ( 0.020)\tLoss 4.9382e+00 (5.6956e+00)\tAcc@1  10.55 (  4.79)\tAcc@5  27.73 ( 13.71)\n",
      "Epoch: [0][2200/5005]\tTime  1.750 ( 1.364)\tData  0.000 ( 0.019)\tLoss 4.8892e+00 (5.6773e+00)\tAcc@1  10.16 (  4.92)\tAcc@5  27.73 ( 13.98)\n",
      "Epoch: [0][2250/5005]\tTime  1.338 ( 1.364)\tData  0.000 ( 0.019)\tLoss 4.8827e+00 (5.6596e+00)\tAcc@1  10.94 (  5.03)\tAcc@5  25.00 ( 14.24)\n",
      "Epoch: [0][2300/5005]\tTime  1.601 ( 1.366)\tData  0.000 ( 0.019)\tLoss 4.9884e+00 (5.6414e+00)\tAcc@1   6.64 (  5.16)\tAcc@5  21.88 ( 14.52)\n",
      "Epoch: [0][2350/5005]\tTime  1.466 ( 1.366)\tData  0.000 ( 0.019)\tLoss 4.6714e+00 (5.6238e+00)\tAcc@1  11.72 (  5.28)\tAcc@5  28.52 ( 14.80)\n",
      "Epoch: [0][2400/5005]\tTime  1.353 ( 1.367)\tData  0.000 ( 0.019)\tLoss 4.7778e+00 (5.6058e+00)\tAcc@1  13.67 (  5.40)\tAcc@5  28.12 ( 15.09)\n",
      "Epoch: [0][2450/5005]\tTime  1.557 ( 1.368)\tData  0.000 ( 0.019)\tLoss 4.6392e+00 (5.5884e+00)\tAcc@1  11.72 (  5.53)\tAcc@5  29.30 ( 15.36)\n",
      "Epoch: [0][2500/5005]\tTime  1.218 ( 1.369)\tData  0.000 ( 0.019)\tLoss 4.8966e+00 (5.5714e+00)\tAcc@1  11.72 (  5.66)\tAcc@5  28.12 ( 15.64)\n",
      "Epoch: [0][2550/5005]\tTime  1.353 ( 1.370)\tData  0.000 ( 0.019)\tLoss 4.7056e+00 (5.5543e+00)\tAcc@1  10.16 (  5.78)\tAcc@5  26.56 ( 15.90)\n",
      "Epoch: [0][2600/5005]\tTime  1.342 ( 1.370)\tData  0.000 ( 0.019)\tLoss 4.7452e+00 (5.5375e+00)\tAcc@1  10.94 (  5.91)\tAcc@5  28.12 ( 16.17)\n",
      "Epoch: [0][2650/5005]\tTime  1.273 ( 1.371)\tData  0.000 ( 0.019)\tLoss 4.6427e+00 (5.5209e+00)\tAcc@1  12.11 (  6.04)\tAcc@5  30.47 ( 16.43)\n",
      "Epoch: [0][2700/5005]\tTime  1.121 ( 1.372)\tData  0.000 ( 0.019)\tLoss 4.6820e+00 (5.5052e+00)\tAcc@1  10.55 (  6.15)\tAcc@5  28.91 ( 16.69)\n",
      "Epoch: [0][2750/5005]\tTime  1.979 ( 1.373)\tData  0.000 ( 0.019)\tLoss 4.5154e+00 (5.4892e+00)\tAcc@1  16.02 (  6.28)\tAcc@5  33.59 ( 16.95)\n",
      "Epoch: [0][2800/5005]\tTime  1.338 ( 1.373)\tData  0.000 ( 0.019)\tLoss 4.6806e+00 (5.4732e+00)\tAcc@1  10.55 (  6.41)\tAcc@5  24.61 ( 17.20)\n",
      "Epoch: [0][2850/5005]\tTime  1.155 ( 1.373)\tData  0.000 ( 0.019)\tLoss 4.5303e+00 (5.4571e+00)\tAcc@1  14.84 (  6.53)\tAcc@5  31.25 ( 17.48)\n",
      "Epoch: [0][2900/5005]\tTime  0.990 ( 1.373)\tData  0.000 ( 0.019)\tLoss 4.5836e+00 (5.4415e+00)\tAcc@1  14.06 (  6.66)\tAcc@5  30.86 ( 17.73)\n",
      "Epoch: [0][2950/5005]\tTime  1.437 ( 1.373)\tData  0.000 ( 0.019)\tLoss 4.6316e+00 (5.4268e+00)\tAcc@1  13.28 (  6.78)\tAcc@5  29.69 ( 17.97)\n",
      "Epoch: [0][3000/5005]\tTime  1.330 ( 1.374)\tData  0.000 ( 0.019)\tLoss 4.3247e+00 (5.4114e+00)\tAcc@1  14.84 (  6.90)\tAcc@5  35.94 ( 18.21)\n",
      "Epoch: [0][3050/5005]\tTime  0.999 ( 1.375)\tData  0.000 ( 0.019)\tLoss 4.4914e+00 (5.3961e+00)\tAcc@1  16.02 (  7.03)\tAcc@5  32.81 ( 18.47)\n",
      "Epoch: [0][3100/5005]\tTime  1.190 ( 1.375)\tData  0.000 ( 0.019)\tLoss 4.4801e+00 (5.3816e+00)\tAcc@1  12.89 (  7.15)\tAcc@5  35.55 ( 18.71)\n",
      "Epoch: [0][3150/5005]\tTime  1.224 ( 1.375)\tData  0.000 ( 0.019)\tLoss 4.3371e+00 (5.3669e+00)\tAcc@1  15.62 (  7.27)\tAcc@5  37.11 ( 18.95)\n",
      "Epoch: [0][3200/5005]\tTime  1.929 ( 1.375)\tData  0.000 ( 0.019)\tLoss 4.2576e+00 (5.3521e+00)\tAcc@1  17.58 (  7.40)\tAcc@5  34.77 ( 19.20)\n",
      "Epoch: [0][3250/5005]\tTime  1.597 ( 1.375)\tData  0.000 ( 0.019)\tLoss 4.4340e+00 (5.3381e+00)\tAcc@1  14.45 (  7.52)\tAcc@5  32.03 ( 19.42)\n",
      "Epoch: [0][3300/5005]\tTime  1.289 ( 1.375)\tData  0.000 ( 0.019)\tLoss 4.2897e+00 (5.3243e+00)\tAcc@1  16.80 (  7.64)\tAcc@5  38.28 ( 19.66)\n",
      "Epoch: [0][3350/5005]\tTime  1.242 ( 1.375)\tData  0.000 ( 0.019)\tLoss 4.4595e+00 (5.3105e+00)\tAcc@1  14.84 (  7.76)\tAcc@5  32.81 ( 19.89)\n",
      "Epoch: [0][3400/5005]\tTime  1.289 ( 1.375)\tData  0.000 ( 0.019)\tLoss 4.3649e+00 (5.2966e+00)\tAcc@1  14.06 (  7.88)\tAcc@5  32.03 ( 20.12)\n",
      "Epoch: [0][3450/5005]\tTime  1.299 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.2226e+00 (5.2832e+00)\tAcc@1  17.58 (  8.00)\tAcc@5  33.59 ( 20.35)\n",
      "Epoch: [0][3500/5005]\tTime  1.771 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.6748e+00 (5.2696e+00)\tAcc@1  11.72 (  8.12)\tAcc@5  31.64 ( 20.57)\n",
      "Epoch: [0][3550/5005]\tTime  2.079 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.6386e+00 (5.2562e+00)\tAcc@1  13.28 (  8.25)\tAcc@5  33.59 ( 20.80)\n",
      "Epoch: [0][3600/5005]\tTime  1.155 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.1738e+00 (5.2427e+00)\tAcc@1  19.14 (  8.37)\tAcc@5  41.41 ( 21.04)\n",
      "Epoch: [0][3650/5005]\tTime  1.683 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.2167e+00 (5.2297e+00)\tAcc@1  19.53 (  8.48)\tAcc@5  41.80 ( 21.26)\n",
      "Epoch: [0][3700/5005]\tTime  1.132 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.2635e+00 (5.2169e+00)\tAcc@1  14.06 (  8.60)\tAcc@5  37.89 ( 21.49)\n",
      "Epoch: [0][3750/5005]\tTime  1.337 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.4165e+00 (5.2038e+00)\tAcc@1  14.45 (  8.72)\tAcc@5  32.81 ( 21.72)\n",
      "Epoch: [0][3800/5005]\tTime  1.286 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.1853e+00 (5.1913e+00)\tAcc@1  19.14 (  8.84)\tAcc@5  41.02 ( 21.93)\n",
      "Epoch: [0][3850/5005]\tTime  0.993 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.2416e+00 (5.1785e+00)\tAcc@1  19.92 (  8.96)\tAcc@5  38.28 ( 22.15)\n",
      "Epoch: [0][3900/5005]\tTime  1.340 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.1141e+00 (5.1664e+00)\tAcc@1  18.75 (  9.07)\tAcc@5  39.45 ( 22.36)\n",
      "Epoch: [0][3950/5005]\tTime  1.149 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.2221e+00 (5.1539e+00)\tAcc@1  22.66 (  9.18)\tAcc@5  44.92 ( 22.57)\n",
      "Epoch: [0][4000/5005]\tTime  1.334 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.2363e+00 (5.1422e+00)\tAcc@1  17.58 (  9.30)\tAcc@5  39.84 ( 22.77)\n",
      "Epoch: [0][4050/5005]\tTime  1.285 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.0107e+00 (5.1301e+00)\tAcc@1  19.53 (  9.42)\tAcc@5  45.31 ( 22.99)\n",
      "Epoch: [0][4100/5005]\tTime  1.326 ( 1.376)\tData  0.000 ( 0.019)\tLoss 3.9629e+00 (5.1179e+00)\tAcc@1  21.88 (  9.53)\tAcc@5  44.92 ( 23.20)\n",
      "Epoch: [0][4150/5005]\tTime  1.793 ( 1.377)\tData  0.000 ( 0.019)\tLoss 4.3254e+00 (5.1057e+00)\tAcc@1  16.41 (  9.65)\tAcc@5  36.33 ( 23.42)\n",
      "Epoch: [0][4200/5005]\tTime  1.153 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.1117e+00 (5.0937e+00)\tAcc@1  19.92 (  9.76)\tAcc@5  43.75 ( 23.62)\n",
      "Epoch: [0][4250/5005]\tTime  1.057 ( 1.377)\tData  0.000 ( 0.019)\tLoss 3.9267e+00 (5.0819e+00)\tAcc@1  21.48 (  9.88)\tAcc@5  44.53 ( 23.83)\n",
      "Epoch: [0][4300/5005]\tTime  1.290 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.0555e+00 (5.0701e+00)\tAcc@1  16.80 ( 10.00)\tAcc@5  40.23 ( 24.04)\n",
      "Epoch: [0][4350/5005]\tTime  1.297 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.1029e+00 (5.0585e+00)\tAcc@1  15.23 ( 10.11)\tAcc@5  38.28 ( 24.24)\n",
      "Epoch: [0][4400/5005]\tTime  1.205 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.3036e+00 (5.0474e+00)\tAcc@1  19.14 ( 10.22)\tAcc@5  39.84 ( 24.43)\n",
      "Epoch: [0][4450/5005]\tTime  1.616 ( 1.376)\tData  0.000 ( 0.019)\tLoss 3.8437e+00 (5.0361e+00)\tAcc@1  23.05 ( 10.34)\tAcc@5  42.97 ( 24.63)\n",
      "Epoch: [0][4500/5005]\tTime  2.087 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.1674e+00 (5.0246e+00)\tAcc@1  17.19 ( 10.45)\tAcc@5  36.33 ( 24.83)\n",
      "Epoch: [0][4550/5005]\tTime  1.235 ( 1.376)\tData  0.000 ( 0.019)\tLoss 3.8155e+00 (5.0135e+00)\tAcc@1  22.27 ( 10.56)\tAcc@5  44.92 ( 25.03)\n",
      "Epoch: [0][4600/5005]\tTime  1.207 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.1197e+00 (5.0022e+00)\tAcc@1  19.92 ( 10.67)\tAcc@5  42.58 ( 25.23)\n",
      "Epoch: [0][4650/5005]\tTime  1.114 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.3313e+00 (4.9912e+00)\tAcc@1  17.97 ( 10.78)\tAcc@5  38.67 ( 25.42)\n",
      "Epoch: [0][4700/5005]\tTime  1.056 ( 1.377)\tData  0.000 ( 0.019)\tLoss 4.1188e+00 (4.9803e+00)\tAcc@1  18.36 ( 10.89)\tAcc@5  42.19 ( 25.62)\n",
      "Epoch: [0][4750/5005]\tTime  1.036 ( 1.377)\tData  0.000 ( 0.019)\tLoss 3.9350e+00 (4.9697e+00)\tAcc@1  18.36 ( 11.00)\tAcc@5  42.19 ( 25.81)\n",
      "Epoch: [0][4800/5005]\tTime  1.335 ( 1.377)\tData  0.000 ( 0.019)\tLoss 4.0772e+00 (4.9592e+00)\tAcc@1  17.97 ( 11.11)\tAcc@5  39.84 ( 25.99)\n",
      "Epoch: [0][4850/5005]\tTime  1.676 ( 1.376)\tData  0.000 ( 0.019)\tLoss 3.9633e+00 (4.9486e+00)\tAcc@1  23.44 ( 11.21)\tAcc@5  46.09 ( 26.17)\n",
      "Epoch: [0][4900/5005]\tTime  1.153 ( 1.376)\tData  0.000 ( 0.019)\tLoss 4.0190e+00 (4.9379e+00)\tAcc@1  21.09 ( 11.32)\tAcc@5  44.14 ( 26.36)\n",
      "Epoch: [0][4950/5005]\tTime  1.230 ( 1.376)\tData  0.000 ( 0.019)\tLoss 3.8869e+00 (4.9276e+00)\tAcc@1  21.09 ( 11.43)\tAcc@5  43.36 ( 26.56)\n",
      "Epoch: [0][5000/5005]\tTime  1.343 ( 1.376)\tData  0.000 ( 0.019)\tLoss 3.8353e+00 (4.9172e+00)\tAcc@1  20.31 ( 11.54)\tAcc@5  46.09 ( 26.74)\n",
      "Test: [  0/196]\tTime  3.343 ( 3.343)\tLoss 2.7005e+00 (2.7005e+00)\tAcc@1  35.16 ( 35.16)\tAcc@5  72.27 ( 72.27)\n",
      "Test: [ 50/196]\tTime  0.374 ( 0.421)\tLoss 2.8388e+00 (3.5711e+00)\tAcc@1  37.11 ( 23.65)\tAcc@5  62.11 ( 50.07)\n",
      "Test: [100/196]\tTime  0.379 ( 0.401)\tLoss 5.2309e+00 (3.7411e+00)\tAcc@1   1.95 ( 22.51)\tAcc@5  18.75 ( 47.05)\n",
      "Test: [150/196]\tTime  0.380 ( 0.395)\tLoss 5.2770e+00 (3.8949e+00)\tAcc@1   7.42 ( 20.93)\tAcc@5  20.31 ( 44.15)\n",
      " * Acc@1 21.148 Acc@5 43.990\n",
      "lr: [0.09999383162408304]\n",
      "Epoch Time: 116.1939193367958 minutes\n",
      "Epoch: [1][   0/5005]\tTime  3.525 ( 3.525)\tData  3.112 ( 3.112)\tLoss 3.6849e+00 (3.6849e+00)\tAcc@1  24.61 ( 24.61)\tAcc@5  51.56 ( 51.56)\n",
      "Epoch: [1][  50/5005]\tTime  1.314 ( 1.299)\tData  0.000 ( 0.071)\tLoss 4.0846e+00 (3.8818e+00)\tAcc@1  20.31 ( 22.11)\tAcc@5  42.97 ( 45.21)\n"
     ]
    }
   ],
   "source": [
    "best_acc1 = 0\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    #Implement Learning Rate Adjustment\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "    wandb.log({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    })\n",
    "    \n",
    "    t2 = time.time()\n",
    "    \n",
    "    print(\"Epoch Time:\",(t2-t1)/60,\"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d70b59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
