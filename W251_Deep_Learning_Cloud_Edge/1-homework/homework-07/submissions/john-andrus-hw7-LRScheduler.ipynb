{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Imports\n",
    "1. time - Record start, stop, elapsed time. Good for evaluating model training times\n",
    "2. tqdm - Shows progress bar for training loops\n",
    "3. cv2  - Open source computer vision used to process image files\n",
    "4. PIL Image - Open/modify numpy image files\n",
    "5. numpy, pandas - data analysis, manipulation\n",
    "6. torch - pytorch, deep learning python library\n",
    "7. albumentations - Image augmentation for deep learning datasets\n",
    "8. ToTensorV2 - Converts image to a tensor\n",
    "9. torch.utils.data DataLoader, Dataset - prebuilt data set and data loading code\n",
    "10. timm - python deep learning library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T13:57:20.342176Z",
     "iopub.status.busy": "2021-06-21T13:57:20.341784Z",
     "iopub.status.idle": "2021-06-21T13:57:32.134581Z",
     "shell.execute_reply": "2021-06-21T13:57:32.132826Z",
     "shell.execute_reply.started": "2021-06-21T13:57:20.342096Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install timm\n",
    "from IPython.display import Image as ImageIpython\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "import timm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Data Files\n",
    "train.csv - training data  \n",
    "test.csv - test data  \n",
    "metadata.csv - actual class names  \n",
    "test, train - folders of images  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T13:57:32.140279Z",
     "iopub.status.busy": "2021-06-21T13:57:32.140023Z",
     "iopub.status.idle": "2021-06-21T13:57:32.780842Z",
     "shell.execute_reply": "2021-06-21T13:57:32.779922Z",
     "shell.execute_reply.started": "2021-06-21T13:57:32.140251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1244\n",
      "-rw-r--r-- 1 nobody nogroup   5062 Jun  7 17:05 metadata.csv\n",
      "-rw-r--r-- 1 nobody nogroup 197871 Jun  7 17:05 sample_submission.csv\n",
      "drwxr-xr-x 2 nobody nogroup      0 Jun  7 17:05 test\n",
      "-rw-r--r-- 1 nobody nogroup 181377 Jun  7 17:05 test.csv\n",
      "drwxr-xr-x 2 nobody nogroup      0 Jun  7 17:06 train\n",
      "-rw-r--r-- 1 nobody nogroup 876817 Jun  7 17:05 train.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../input/midsw251birds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Hyperparameters\n",
    "lr - learning rate  \n",
    "epochs - number of epochs  \n",
    "batch size - number of training examples used to estimate the error gradient  \n",
    "num_workers - number of processes that generate batches in parallel  \n",
    "folds - number of data subdivisions, for 5 folds, typically means 4:1 test to train data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T13:57:32.784810Z",
     "iopub.status.busy": "2021-06-21T13:57:32.784549Z",
     "iopub.status.idle": "2021-06-21T13:57:32.788703Z",
     "shell.execute_reply": "2021-06-21T13:57:32.787916Z",
     "shell.execute_reply.started": "2021-06-21T13:57:32.784782Z"
    }
   },
   "outputs": [],
   "source": [
    "class args:\n",
    "    lr = 0.0001\n",
    "    epochs = 5\n",
    "    batch_size = 32\n",
    "    num_workers = 8\n",
    "    folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the data into train, validation, and test data\n",
    "alldf - All examples  \n",
    "trndf - Training examples  \n",
    "valdf - Validation examples  \n",
    "testdf - Testing examples  \n",
    "metadf - Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T13:57:32.790875Z",
     "iopub.status.busy": "2021-06-21T13:57:32.790322Z",
     "iopub.status.idle": "2021-06-21T13:57:32.880358Z",
     "shell.execute_reply": "2021-06-21T13:57:32.879594Z",
     "shell.execute_reply.started": "2021-06-21T13:57:32.790838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File shapes -- train : (26379, 2), valid : (6595, 2), test : (8244, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/bb99f4bea973.jpg</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/50923ceb3ffd.jpg</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/f9fc3c6da5d7.jpg</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/dfe8cb1855fe.jpg</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train/4fe53a096533.jpg</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filename  label\n",
       "1  train/bb99f4bea973.jpg    147\n",
       "2  train/50923ceb3ffd.jpg    147\n",
       "3  train/f9fc3c6da5d7.jpg    147\n",
       "4  train/dfe8cb1855fe.jpg    147\n",
       "6  train/4fe53a096533.jpg    147"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldf = pd.read_csv('../input/midsw251birds/train.csv')\n",
    "# Split the training dataset into a training and a validation\n",
    "valdf = alldf[::args.folds]\n",
    "trndf = alldf[~alldf.filename.isin(valdf.filename)]\n",
    "# Load our test data\n",
    "tstdf = pd.read_csv('../input/midsw251birds/test.csv')\n",
    "metadf = pd.read_csv('../input/midsw251birds/metadata.csv')\n",
    "metadf = metadf.set_index('label')\n",
    "print(f'File shapes -- train : {trndf.shape}, valid : {valdf.shape}, test : {tstdf.shape}')\n",
    "trndf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Transformations for Train and Test data\n",
    "Perform transformations using albumentations (A):  \n",
    "  \n",
    "Train - 50/50 probability of flipping the image horizontally or transposing  \n",
    "Test - Simply converts image to tensor  \n",
    "  \n",
    "Other possibilities include gaussian noise, motion blur, optical distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T13:57:32.881926Z",
     "iopub.status.busy": "2021-06-21T13:57:32.881615Z",
     "iopub.status.idle": "2021-06-21T13:57:32.890537Z",
     "shell.execute_reply": "2021-06-21T13:57:32.889643Z",
     "shell.execute_reply.started": "2021-06-21T13:57:32.881894Z"
    }
   },
   "outputs": [],
   "source": [
    "imgnetmeans = [0.22363983, 0.18190407, 0.2523437 ]\n",
    "imgnetstds = [0.32451536, 0.2956294,  0.31335256]\n",
    "#Â Using albumentations, check some examples here : https://albumentations.readthedocs.io/en/latest/examples.html \n",
    "def trntransforms():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Transpose(p=0.5),\n",
    "        ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "def tsttransforms():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, df, mode, transform=None):\n",
    "        self.data = df\n",
    "        self.img_dir = '../input/midsw251birds/'\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        fname = self.data.iloc[idx]['filename']\n",
    "        image = cv2.imread(f'{self.img_dir}/{fname}')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image = image)['image']\n",
    "        image = image.float() / 255.\n",
    "        label = -1 if self.mode=='test' else self.data.iloc[idx]['label']\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define + Transform the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T13:57:32.892476Z",
     "iopub.status.busy": "2021-06-21T13:57:32.891885Z",
     "iopub.status.idle": "2021-06-21T13:57:32.902200Z",
     "shell.execute_reply": "2021-06-21T13:57:32.901435Z",
     "shell.execute_reply.started": "2021-06-21T13:57:32.892439Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define our dataset\n",
    "trndataset = BirdDataset(trndf, 'train', trntransforms())\n",
    "valdataset = BirdDataset(valdf, 'valid', tsttransforms())\n",
    "tstdataset = BirdDataset(tstdf, 'test', tsttransforms())\n",
    "loaderargs = {'num_workers' : args.num_workers, 'batch_size':args.batch_size, 'pin_memory': False, 'drop_last': False}\n",
    "trnloader = DataLoader(trndataset, shuffle = True, **loaderargs)\n",
    "valloader = DataLoader(valdataset, shuffle = False, **loaderargs)\n",
    "tstloader = DataLoader(tstdataset, shuffle = False, **loaderargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T13:57:32.903871Z",
     "iopub.status.busy": "2021-06-21T13:57:32.903507Z",
     "iopub.status.idle": "2021-06-21T13:57:40.862843Z",
     "shell.execute_reply": "2021-06-21T13:57:40.862004Z",
     "shell.execute_reply.started": "2021-06-21T13:57:32.903834Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_xl_ra-aac3c00c.pth\" to /root/.cache/torch/hub/checkpoints/mixnet_xl_ra-aac3c00c.pth\n"
     ]
    }
   ],
   "source": [
    "# creates efficientnet-b0 architecture\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = timm.create_model('mixnet_xl', pretrained = True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define optimizer and criterion\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10)\n",
    "num_epochs = args.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T13:57:40.866923Z",
     "iopub.status.busy": "2021-06-21T13:57:40.866668Z",
     "iopub.status.idle": "2021-06-21T13:57:40.872319Z",
     "shell.execute_reply": "2021-06-21T13:57:40.871544Z",
     "shell.execute_reply.started": "2021-06-21T13:57:40.866898Z"
    }
   },
   "outputs": [],
   "source": [
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T13:57:40.875633Z",
     "iopub.status.busy": "2021-06-21T13:57:40.875302Z",
     "iopub.status.idle": "2021-06-21T13:57:40.881749Z",
     "shell.execute_reply": "2021-06-21T13:57:40.880973Z",
     "shell.execute_reply.started": "2021-06-21T13:57:40.875602Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a scheduler which will warmup and cooldown over 20 epochs.\n",
    "# from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "\n",
    "n_epochs = 5\n",
    "n_warmup_epochs = 2\n",
    "n_steps = len(trnloader)\n",
    "\n",
    "scheduler = CosineLRScheduler(\n",
    "            optimizer,\n",
    "            t_initial= n_steps * n_epochs + 1,\n",
    "            lr_min=0.00001,\n",
    "            warmup_lr_init=0.00001,\n",
    "            warmup_t= n_steps * n_warmup_epochs + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T13:57:40.883406Z",
     "iopub.status.busy": "2021-06-21T13:57:40.883058Z",
     "iopub.status.idle": "2021-06-21T14:24:58.220473Z",
     "shell.execute_reply": "2021-06-21T14:24:58.219444Z",
     "shell.execute_reply.started": "2021-06-21T13:57:40.883375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec902bb9ce8241b78e72bea430bc96b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/825 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb35d9457c6430cbb60736c011c308e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid accuracy 0.8881\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aecf03cf765433abd63f20e0900887f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/825 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab7df4ca9a04453b906183c78f07af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid accuracy 0.9318\n",
      "Epoch 2/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac044dc898a842d39065d8107afdf7e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/825 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1897c31ce2474c198672f760f477b553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid accuracy 0.9409\n",
      "Epoch 3/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c35f70e44b04695bdb2d85acd538928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/825 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac387cf7a334a0895f1735fbdc8ae89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid accuracy 0.9404\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb0040674d6448c980cc44dac505805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/825 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84cc1d5111c2470687bba8601e571ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid accuracy 0.9437\n"
     ]
    }
   ],
   "source": [
    "global_step=0\n",
    "\n",
    "since = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    tk0 = tqdm(trnloader, total=int(len(trnloader)))\n",
    "    for step, batch in enumerate(tk0):\n",
    "        inputs = batch[0].to(device, dtype=torch.float)\n",
    "        labels = batch[1].to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step(global_step)\n",
    "        global_step+=1\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        tk0.set_postfix(train_loss=(running_loss / (step+1)))\n",
    "        \n",
    "    valpreds = []\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    tkval = tqdm(valloader, total=int(len(valloader)))\n",
    "    for step, batch in enumerate(tkval):\n",
    "        inputs = batch[0].to(device, dtype=torch.float)\n",
    "        labels = batch[1].to(device).long()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        valpreds .append(outputs)\n",
    "        running_loss += loss.item()\n",
    "        tkval.set_postfix(valid_loss=(running_loss / (step+1)))\n",
    "    preds = torch.cat(valpreds).argmax(1).detach().cpu().numpy()\n",
    "    print(f'Valid accuracy {(valdf.label.values == preds).mean():.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement 1: Changing the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T14:24:58.222233Z",
     "iopub.status.busy": "2021-06-21T14:24:58.221924Z",
     "iopub.status.idle": "2021-06-21T14:24:58.230932Z",
     "shell.execute_reply": "2021-06-21T14:24:58.230127Z",
     "shell.execute_reply.started": "2021-06-21T14:24:58.222203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  219092 KB |    6592 MB |   80431 GB |   80431 GB |\n",
      "|       from large pool |  121124 KB |    6491 MB |   79924 GB |   79924 GB |\n",
      "|       from small pool |   97968 KB |     133 MB |     507 GB |     507 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  219092 KB |    6592 MB |   80431 GB |   80431 GB |\n",
      "|       from large pool |  121124 KB |    6491 MB |   79924 GB |   79924 GB |\n",
      "|       from small pool |   97968 KB |     133 MB |     507 GB |     507 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    7806 MB |    7806 MB |    7806 MB |       0 B  |\n",
      "|       from large pool |    7666 MB |    7666 MB |    7666 MB |       0 B  |\n",
      "|       from small pool |     140 MB |     140 MB |     140 MB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  487468 KB |     930 MB |   28504 GB |   28503 GB |\n",
      "|       from large pool |  485084 KB |     924 MB |   27959 GB |   27958 GB |\n",
      "|       from small pool |    2384 KB |      18 MB |     545 GB |     545 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    1916    |    2477    |   12702 K  |   12700 K  |\n",
      "|       from large pool |      61    |     397    |    5253 K  |    5253 K  |\n",
      "|       from small pool |    1855    |    2123    |    7448 K  |    7446 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    1916    |    2477    |   12702 K  |   12700 K  |\n",
      "|       from large pool |      61    |     397    |    5253 K  |    5253 K  |\n",
      "|       from small pool |    1855    |    2123    |    7448 K  |    7446 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     294    |     294    |     294    |       0    |\n",
      "|       from large pool |     224    |     224    |     224    |       0    |\n",
      "|       from small pool |      70    |      70    |      70    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      76    |     147    |    6616 K  |    6616 K  |\n",
      "|       from large pool |      16    |     134    |    3773 K  |    3773 K  |\n",
      "|       from small pool |      60    |      76    |    2842 K  |    2842 K  |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit \n",
    "tstpreds = []\n",
    "tktst = tqdm(tstloader, total=int(len(tstloader)))\n",
    "for step, batch in enumerate(tktst):\n",
    "    inputs = batch[0].to(device, dtype=torch.float)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        tstpreds.append(outputs)\n",
    "predicted_labels = torch.cat(tstpreds).argmax(1).detach().cpu().numpy()\n",
    "tstdf['label'] = predicted_labels\n",
    "\n",
    "tstdf.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T14:24:58.232308Z",
     "iopub.status.busy": "2021-06-21T14:24:58.232067Z",
     "iopub.status.idle": "2021-06-21T14:24:58.239749Z",
     "shell.execute_reply": "2021-06-21T14:24:58.238976Z",
     "shell.execute_reply.started": "2021-06-21T14:24:58.232284Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# args.batch_size = 10\n",
    "# # creates mixnet_xl architecture\n",
    "# device = torch.device(\"cuda:0\")\n",
    "# model = timm.create_model('mixnet_xl', pretrained = True)\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Define optimizer and criterion\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=10)\n",
    "# num_epochs = args.epochs\n",
    "\n",
    "# #Reduce batch size for memory considerations\n",
    "# # args.batch_size = 6\n",
    "\n",
    "# since = time.time()\n",
    "# for epoch in range(num_epochs):\n",
    "#     print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "#     scheduler.step()\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     tk0 = tqdm(trnloader, total=int(len(trnloader)))\n",
    "#     for step, batch in enumerate(tk0):\n",
    "#         inputs = batch[0].to(device, dtype=torch.float)\n",
    "#         labels = batch[1].to(device).long()\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "#         tk0.set_postfix(train_loss=(running_loss / (step+1)))\n",
    "        \n",
    "#     valpreds = []\n",
    "#     model.eval()\n",
    "#     running_loss = 0.0\n",
    "#     tkval = tqdm(valloader, total=int(len(valloader)))\n",
    "#     for step, batch in enumerate(tkval):\n",
    "#         inputs = batch[0].to(device, dtype=torch.float)\n",
    "#         labels = batch[1].to(device).long()\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#         valpreds .append(outputs)\n",
    "#         running_loss += loss.item()\n",
    "#         tkval.set_postfix(valid_loss=(running_loss / (step+1)))\n",
    "#     preds = torch.cat(valpreds).argmax(1).detach().cpu().numpy()\n",
    "#     print(f'Valid accuracy {(valdf.label.values == preds).mean():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
